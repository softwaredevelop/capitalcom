{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETF Screener and Watchlist Creator\n",
    "\n",
    "This notebook implements an efficient, multi-step workflow to find ETFs based on specific criteria and automatically organize them into a new watchlist. It addresses the challenge of API rate limits by using bulk data fetching methods.\n",
    "\n",
    "### Workflow:\n",
    "1.  **Discover All ETF Epics:** We will navigate the market hierarchy to get a complete list of all available ETF epics.\n",
    "2.  **Batch Fetch Details:** We will fetch the detailed data for all discovered ETFs in batches of 50 to minimize API calls.\n",
    "3.  **Filter Locally:** We will load all the data into a pandas DataFrame and apply our desired filters locally (e.g., find ETFs that are `TRADEABLE` and have a `REGULAR` market mode).\n",
    "4.  **Create Watchlist:** Finally, we will take the filtered list of epics and create a new, dedicated watchlist on Capital.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "project_root = notebook_dir.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.capitalcom_bot.client_factory import get_client  # noqa: E402\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\")\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Discover All ETF Epics\n",
    "\n",
    "First, we need to get a list of all ETF epics. We assume ETFs are under a specific market navigation node. *Note: You may need to adjust the `etf_node_id` based on the output of `setup_api_workflow.ipynb`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_etf_epics = []\n",
    "etf_node_id = \"hierarchy_v1.etf_group.etf\"  # This might need adjustment!\n",
    "\n",
    "try:\n",
    "    with get_client(demo_mode=True) as client:\n",
    "        logger.info(f\"Fetching all markets from node: {etf_node_id}\")\n",
    "        # The API might paginate, but for now we assume it returns all in one go.\n",
    "        etf_group_content = client.get_markets_by_category(etf_node_id)\n",
    "        if etf_group_content.get(\"markets\"):\n",
    "            all_etf_epics = [market[\"epic\"] for market in etf_group_content[\"markets\"]]\n",
    "            logger.success(f\"Discovered {len(all_etf_epics)} total ETF epics.\")\n",
    "        else:\n",
    "            logger.warning(\"No markets found in the specified node.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to discover ETF epics: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Batch Fetch Details for All ETFs\n",
    "\n",
    "Now we use the powerful `epics` parameter of the `/markets` endpoint to fetch details in batches, avoiding thousands of individual API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_etf_details = []\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "if all_etf_epics:\n",
    "    try:\n",
    "        with get_client(demo_mode=True) as client:\n",
    "            num_batches = math.ceil(len(all_etf_epics) / BATCH_SIZE)\n",
    "            logger.info(f\"Fetching details in {num_batches} batches of {BATCH_SIZE}...\")\n",
    "\n",
    "            for i in range(0, len(all_etf_epics), BATCH_SIZE):\n",
    "                batch_epics = all_etf_epics[i : i + BATCH_SIZE]\n",
    "                logger.debug(f\"Fetching batch {i // BATCH_SIZE + 1}/{num_batches}...\")\n",
    "\n",
    "                response_model = client.get_markets_by_epics(batch_epics)\n",
    "\n",
    "                # This ensures the dictionary keys match the original JSON field names (aliases).\n",
    "                batch_details = [\n",
    "                    detail.model_dump(by_alias=True)\n",
    "                    for detail in response_model.market_details\n",
    "                ]\n",
    "                all_etf_details.extend(batch_details)\n",
    "\n",
    "            logger.success(\n",
    "                f\"Successfully fetched details for {len(all_etf_details)} ETFs.\"\n",
    "            )\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed during batch fetch: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load to DataFrame and Filter Locally\n",
    "\n",
    "With all the data now in memory, we can use the power of pandas to perform complex filtering without any more API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_epics = []\n",
    "\n",
    "if all_etf_details:\n",
    "    df_etfs = pd.json_normalize(all_etf_details)\n",
    "    logger.info(f\"Created DataFrame with {len(df_etfs)} ETFs.\")\n",
    "\n",
    "    tradeable_filter = df_etfs[\"snapshot.marketStatus\"] == \"TRADEABLE\"\n",
    "\n",
    "    def check_regular_mode(modes):\n",
    "        if isinstance(modes, list):\n",
    "            return \"REGULAR\" in modes\n",
    "        return False\n",
    "\n",
    "    regular_mode_filter = df_etfs[\"snapshot.marketModes\"].apply(check_regular_mode)\n",
    "\n",
    "    df_filtered = df_etfs[tradeable_filter & regular_mode_filter]\n",
    "\n",
    "    logger.success(f\"Found {len(df_filtered)} ETFs matching all criteria.\")\n",
    "\n",
    "    display_columns = [\n",
    "        \"instrument.epic\",\n",
    "        \"instrument.name\",\n",
    "        \"snapshot.marketStatus\",\n",
    "        \"snapshot.marketModes\",\n",
    "    ]\n",
    "    display(df_filtered[display_columns])\n",
    "\n",
    "    filtered_epics = df_filtered[\"instrument.epic\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create a New Watchlist from the Filtered Results\n",
    "\n",
    "Finally, we take our list of filtered epics and create a new watchlist on Capital.com for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_watchlist_name = \"Tradeable ETFs\"\n",
    "\n",
    "if filtered_epics:\n",
    "    try:\n",
    "        with get_client(demo_mode=True) as client:\n",
    "            # Clean up any old watchlist with the same name for a clean, repeatable run\n",
    "            logger.info(\"Checking for existing watchlists to clean up...\")\n",
    "            existing_watchlists = client.get_watchlists()\n",
    "            for wl in existing_watchlists.watchlists:\n",
    "                if wl.name == new_watchlist_name:\n",
    "                    logger.warning(\n",
    "                        f\"Deleting existing watchlist named '{new_watchlist_name}' (ID: {wl.id}).\"\n",
    "                    )\n",
    "                    client.delete_watchlist(wl.id)\n",
    "\n",
    "            # Create the new watchlist with all our filtered epics in one go\n",
    "            logger.info(\n",
    "                f\"Creating new watchlist '{new_watchlist_name}' with {len(filtered_epics)} ETFs...\"\n",
    "            )\n",
    "            response = client.create_watchlist(\n",
    "                name=new_watchlist_name, epics=filtered_epics\n",
    "            )\n",
    "\n",
    "            logger.success(\n",
    "                f\"Successfully created watchlist '{new_watchlist_name}' with ID {response.watchlist_id}.\"\n",
    "            )\n",
    "            print(\n",
    "                \"\\nYou can now check your Capital.com account to see the new watchlist!\"\n",
    "            )\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create watchlist: {e}\", exc_info=True)\n",
    "else:\n",
    "    logger.info(\"No ETFs to add to a watchlist based on the filters.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capitalcom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
